{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ipyrad API with *Eurycea longicauda* samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you are in a Python 2 environment in the cluster. Or that you have installed a Python 2 kernel in your jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#conda create -n py27 python=2.7\n",
    "source activate py27\n",
    "#conda install notebook ipykernel\n",
    "#ipython kernel install --user\n",
    "\n",
    "#To deactivate the conda environment: \n",
    "#source deactivate\n",
    "\n",
    "cd /rigel/edu/w4050/users/ngs2116/ipyrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the correct packages and connect to the ipcluster that you started with an sbatch job submission on the cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rigel/home/ngs2116/miniconda3/envs/py27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import ipyrad as ip\n",
    "import ipyparallel as ipp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open up a terminal from the home page of Jupyter notebook. \n",
    "\n",
    "Type `ipcluster start --n=24`. `n` is the number of jobs that can run simutaenously and will likely be the number of cores that are available to you. You can also name the ipcluster profile `ipcluster start --n=24 --profile='neha'` and then you'd use `ipyclient=ipp.Client(profile='neha')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host compute node: [24 cores] on node161\n",
      "host compute node: [24 cores] on node162\n"
     ]
    }
   ],
   "source": [
    "## connect to the client\n",
    "ipyclient = ipp.Client(profile='MPI')\n",
    "\n",
    "## use ipyrad to print cluster info\n",
    "ip.cluster_info(ipyclient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples are spread into six libraries distributed across 3 lanes, and so I will create 18 different class objects, one for each library in each lane, to run step 1. After step 1, I'll merge all the reads into one file that encompasses the full assembly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Assembly: ACAGTG1\n",
      "New Assembly: ACAGTG2\n",
      "New Assembly: ACAGTG3\n",
      "New Assembly: ATCACG1\n",
      "New Assembly: ATCACG2\n",
      "New Assembly: ATCACG3\n",
      "New Assembly: CGATGT1\n",
      "New Assembly: CGATGT2\n",
      "New Assembly: CGATGT3\n",
      "New Assembly: GCCAAT1\n",
      "New Assembly: GCCAAT2\n",
      "New Assembly: GCCAAT3\n",
      "New Assembly: TGACCA1\n",
      "New Assembly: TGACCA2\n",
      "New Assembly: TGACCA3\n",
      "New Assembly: TTAGGC1\n",
      "New Assembly: TTAGGC2\n",
      "New Assembly: TTAGGC3\n"
     ]
    }
   ],
   "source": [
    "#Creating a new class object for ACAGTG pool in lane 1. \n",
    "ACAGTG1 = ip.Assembly(\"ACAGTG1\")\n",
    "ACAGTG2 = ip.Assembly(\"ACAGTG2\")\n",
    "ACAGTG3 = ip.Assembly(\"ACAGTG3\")\n",
    "      \n",
    "ATCACG1 = ip.Assembly(\"ATCACG1\")\n",
    "ATCACG2 = ip.Assembly(\"ATCACG2\")\n",
    "ATCACG3 = ip.Assembly(\"ATCACG3\")\n",
    "\n",
    "CGATGT1 = ip.Assembly(\"CGATGT1\")\n",
    "CGATGT2 = ip.Assembly(\"CGATGT2\")\n",
    "CGATGT3 = ip.Assembly(\"CGATGT3\")\n",
    "\n",
    "GCCAAT1 = ip.Assembly(\"GCCAAT1\")\n",
    "GCCAAT2 = ip.Assembly(\"GCCAAT2\")\n",
    "GCCAAT3 = ip.Assembly(\"GCCAAT3\")\n",
    "\n",
    "TGACCA1 = ip.Assembly(\"TGACCA1\")\n",
    "TGACCA2 = ip.Assembly(\"TGACCA2\")\n",
    "TGACCA3 = ip.Assembly(\"TGACCA3\")\n",
    "\n",
    "TTAGGC1 = ip.Assembly(\"TTAGGC1\")\n",
    "TTAGGC2 = ip.Assembly(\"TTAGGC2\")\n",
    "TTAGGC3 = ip.Assembly(\"TTAGGC3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   assembly_name               ACAGTG1                                      \n",
      "1   project_dir                 /rigel/edu/w4050/users/ngs2116/ipyrad        \n",
      "2   raw_fastq_path                                                           \n",
      "3   barcodes_path               /rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_ACAGTG.txt\n",
      "4   sorted_fastq_path           /rigel/edu/w4050/users/ngs2116/ipyrad/ACAGTG1_fastqs/*.gz\n",
      "5   assembly_method             denovo                                       \n",
      "6   reference_sequence                                                       \n",
      "7   datatype                    pairddrad                                    \n",
      "8   restriction_overhang        ('CATGC', 'AATTC')                           \n",
      "9   max_low_qual_bases          5                                            \n",
      "10  phred_Qscore_offset         33                                           \n",
      "11  mindepth_statistical        6                                            \n",
      "12  mindepth_majrule            6                                            \n",
      "13  maxdepth                    10000                                        \n",
      "14  clust_threshold             0.85                                         \n",
      "15  max_barcode_mismatch        0                                            \n",
      "16  filter_adapters             2                                            \n",
      "17  filter_min_trim_len         75                                           \n",
      "18  max_alleles_consens         3                                            \n",
      "19  max_Ns_consens              (5, 5)                                       \n",
      "20  max_Hs_consens              (8, 8)                                       \n",
      "21  min_samples_locus           4                                            \n",
      "22  max_SNPs_locus              (20, 20)                                     \n",
      "23  max_Indels_locus            (8, 8)                                       \n",
      "24  max_shared_Hs_locus         0.5                                          \n",
      "25  trim_reads                  (0, 0, 0, 0)                                 \n",
      "26  trim_loci                   (0, 0, 0, 0)                                 \n",
      "27  output_formats              ('p', 's', 'k', 'v')                         \n",
      "28  pop_assign_file                                                          \n",
      "0   assembly_name               TTAGGC3                                      \n",
      "1   project_dir                 /rigel/edu/w4050/users/ngs2116/ipyrad        \n",
      "2   raw_fastq_path                                                           \n",
      "3   barcodes_path               /rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_TTAGGC.txt\n",
      "4   sorted_fastq_path           /rigel/edu/w4050/users/ngs2116/ipyrad/TTAGGC3_fastqs/*.gz\n",
      "5   assembly_method             denovo                                       \n",
      "6   reference_sequence                                                       \n",
      "7   datatype                    pairddrad                                    \n",
      "8   restriction_overhang        ('CATGC', 'AATTC')                           \n",
      "9   max_low_qual_bases          5                                            \n",
      "10  phred_Qscore_offset         33                                           \n",
      "11  mindepth_statistical        6                                            \n",
      "12  mindepth_majrule            6                                            \n",
      "13  maxdepth                    10000                                        \n",
      "14  clust_threshold             0.85                                         \n",
      "15  max_barcode_mismatch        0                                            \n",
      "16  filter_adapters             2                                            \n",
      "17  filter_min_trim_len         75                                           \n",
      "18  max_alleles_consens         3                                            \n",
      "19  max_Ns_consens              (5, 5)                                       \n",
      "20  max_Hs_consens              (8, 8)                                       \n",
      "21  min_samples_locus           4                                            \n",
      "22  max_SNPs_locus              (20, 20)                                     \n",
      "23  max_Indels_locus            (8, 8)                                       \n",
      "24  max_shared_Hs_locus         0.5                                          \n",
      "25  trim_reads                  (0, 0, 0, 0)                                 \n",
      "26  trim_loci                   (0, 0, 0, 0)                                 \n",
      "27  output_formats              ['p', 's', 'v']                              \n",
      "28  pop_assign_file                                                          \n"
     ]
    }
   ],
   "source": [
    "## setting/modifying parameters for this ACAGTG objects from each lane\n",
    "ACAGTG1.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "ACAGTG1.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_ACAGTG.txt')\n",
    "ACAGTG1.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/ACAGTG1_fastqs/*.gz')\n",
    "ACAGTG1.set_params('filter_adapters', 2)\n",
    "ACAGTG1.set_params('datatype', 'pairddrad')\n",
    "ACAGTG1.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "ACAGTG1.set_params('filter_min_trim_len', '75')\n",
    "ACAGTG1.set_params('max_alleles_consens', 3)\n",
    "ACAGTG1.set_params('output_formats', \"p, s, k, v\")\n",
    "ACAGTG1.get_params() # prints the parameters to the screen\n",
    "\n",
    "ACAGTG2.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "ACAGTG2.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_ACAGTG.txt')\n",
    "ACAGTG2.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/ACAGTG2_fastqs/*.gz')\n",
    "ACAGTG2.set_params('filter_adapters', 2)\n",
    "ACAGTG2.set_params('datatype', 'pairddrad')\n",
    "ACAGTG2.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "ACAGTG2.set_params('filter_min_trim_len', '75')\n",
    "ACAGTG2.set_params('output_formats', \"p, s, k, v\")\n",
    "ACAGTG2.set_params('max_alleles_consens', 3)\n",
    "\n",
    "ACAGTG3.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "ACAGTG3.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_ACAGTG.txt')\n",
    "ACAGTG3.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/ACAGTG2_fastqs/*.gz')\n",
    "ACAGTG3.set_params('filter_adapters', 2)\n",
    "ACAGTG3.set_params('datatype', 'pairddrad')\n",
    "ACAGTG3.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "ACAGTG3.set_params('filter_min_trim_len', '75')\n",
    "ACAGTG3.set_params('max_alleles_consens', 3)\n",
    "ACAGTG3.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "## setting/modifying parameters for this ATCACG objects from each lane\n",
    "ATCACG1.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "ATCACG1.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_ATCACG.txt')\n",
    "ATCACG1.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/ATCACG1_fastqs/*.gz')\n",
    "ATCACG1.set_params('filter_adapters', 2)\n",
    "ATCACG1.set_params('datatype', 'pairddrad')\n",
    "ATCACG1.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "ATCACG1.set_params('filter_min_trim_len', '75')\n",
    "ATCACG1.set_params('max_alleles_consens', 3)\n",
    "ATCACG1.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "ATCACG2.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "ATCACG2.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_ATCACG.txt')\n",
    "ATCACG2.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/ATCACG2_fastqs/*.gz')\n",
    "ATCACG2.set_params('filter_adapters', 2)\n",
    "ATCACG2.set_params('datatype', 'pairddrad')\n",
    "ATCACG2.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "ATCACG2.set_params('filter_min_trim_len', '75')\n",
    "ATCACG2.set_params('max_alleles_consens', 3)\n",
    "ATCACG2.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "ATCACG3.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "ATCACG3.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_ATCACG.txt')\n",
    "ATCACG3.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/ATCACG3_fastqs/*.gz')\n",
    "ATCACG3.set_params('filter_adapters', 2)\n",
    "ATCACG3.set_params('datatype', 'pairddrad')\n",
    "ATCACG3.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "ATCACG3.set_params('filter_min_trim_len', '75')\n",
    "ATCACG3.set_params('max_alleles_consens', 3)\n",
    "ATCACG3.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "## setting/modifying parameters for this CGATGT objects from each lane\n",
    "CGATGT1.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "CGATGT1.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_CGATGT.txt')\n",
    "CGATGT1.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/CGATGT1_fastqs/*.gz')\n",
    "CGATGT1.set_params('filter_adapters', 2)\n",
    "CGATGT1.set_params('datatype', 'pairddrad')\n",
    "CGATGT1.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "CGATGT1.set_params('filter_min_trim_len', '75')\n",
    "CGATGT1.set_params('max_alleles_consens', 3)\n",
    "CGATGT1.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "CGATGT2.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "CGATGT2.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_CGATGT.txt')\n",
    "CGATGT2.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/CGATGT2_fastqs/*.gz')\n",
    "CGATGT2.set_params('filter_adapters', 2)\n",
    "CGATGT2.set_params('datatype', 'pairddrad')\n",
    "CGATGT2.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "CGATGT2.set_params('filter_min_trim_len', '75')\n",
    "CGATGT2.set_params('max_alleles_consens', 3)\n",
    "CGATGT2.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "CGATGT3.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "CGATGT3.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_CGATGT.txt')\n",
    "CGATGT3.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/CGATGT3_fastqs/*.gz')\n",
    "CGATGT3.set_params('filter_adapters', 2)\n",
    "CGATGT3.set_params('datatype', 'pairddrad')\n",
    "CGATGT3.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "CGATGT3.set_params('filter_min_trim_len', '75')\n",
    "CGATGT3.set_params('max_alleles_consens', 3)\n",
    "CGATGT3.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "## setting/modifying parameters for this GCCAAT objects from each lane\n",
    "GCCAAT1.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "GCCAAT1.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_GCCAAT.txt')\n",
    "GCCAAT1.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/GCCAAT1_fastqs/*.gz')\n",
    "GCCAAT1.set_params('filter_adapters', 2)\n",
    "GCCAAT1.set_params('datatype', 'pairddrad')\n",
    "GCCAAT1.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "GCCAAT1.set_params('filter_min_trim_len', '75')\n",
    "GCCAAT1.set_params('max_alleles_consens', 3)\n",
    "GCCAAT1.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "GCCAAT2.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "GCCAAT2.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_GCCAAT.txt')\n",
    "GCCAAT2.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/GCCAAT2_fastqs/*.gz')\n",
    "GCCAAT2.set_params('filter_adapters', 2)\n",
    "GCCAAT2.set_params('datatype', 'pairddrad')\n",
    "GCCAAT2.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "GCCAAT2.set_params('filter_min_trim_len', '75')\n",
    "GCCAAT2.set_params('max_alleles_consens', 3)\n",
    "GCCAAT2.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "GCCAAT3.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "GCCAAT3.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_GCCAAT.txt')\n",
    "GCCAAT3.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/GCCAAT3_fastqs/*.gz')\n",
    "GCCAAT3.set_params('filter_adapters', 2)\n",
    "GCCAAT3.set_params('datatype', 'pairddrad')\n",
    "GCCAAT3.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "GCCAAT3.set_params('filter_min_trim_len', '75')\n",
    "GCCAAT3.set_params('max_alleles_consens', 3)\n",
    "GCCAAT3.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "## setting/modifying parameters for this TGACCA objects from each lane\n",
    "TGACCA1.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "TGACCA1.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_TGACCA.txt')\n",
    "TGACCA1.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/TGACCA1_fastqs/*.gz')\n",
    "TGACCA1.set_params('filter_adapters', 2)\n",
    "TGACCA1.set_params('datatype', 'pairddrad')\n",
    "TGACCA1.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "TGACCA1.set_params('filter_min_trim_len', '75')\n",
    "TGACCA1.set_params('max_alleles_consens', 3)\n",
    "TGACCA1.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "TGACCA2.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "TGACCA2.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_TGACCA.txt')\n",
    "TGACCA2.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/TGACCA2_fastqs/*.gz')\n",
    "TGACCA2.set_params('filter_adapters', 2)\n",
    "TGACCA2.set_params('datatype', 'pairddrad')\n",
    "TGACCA2.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "TGACCA2.set_params('filter_min_trim_len', '75')\n",
    "TGACCA2.set_params('max_alleles_consens', 3)\n",
    "TGACCA2.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "TGACCA3.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "TGACCA3.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_TGACCA.txt')\n",
    "TGACCA3.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/TGACCA3_fastqs/*.gz')\n",
    "TGACCA3.set_params('filter_adapters', 2)\n",
    "TGACCA3.set_params('datatype', 'pairddrad')\n",
    "TGACCA3.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "TGACCA3.set_params('filter_min_trim_len', '75')\n",
    "TGACCA3.set_params('max_alleles_consens', 3)\n",
    "TGACCA3.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "## setting/modifying parameters for this TTAGGC objects from each lane\n",
    "TTAGGC1.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "TTAGGC1.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_TTAGGC.txt')\n",
    "TTAGGC1.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/TTAGGC1_fastqs/*.gz')\n",
    "TTAGGC1.set_params('filter_adapters', 2)\n",
    "TTAGGC1.set_params('datatype', 'pairddrad')\n",
    "TTAGGC1.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "TTAGGC1.set_params('filter_min_trim_len', '75')\n",
    "TTAGGC1.set_params('max_alleles_consens', 3)\n",
    "TGACCA1.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "TTAGGC2.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "TTAGGC2.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_TTAGGC.txt')\n",
    "TTAGGC2.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/TTAGGC2_fastqs/*.gz')\n",
    "TTAGGC2.set_params('filter_adapters', 2)\n",
    "TTAGGC2.set_params('datatype', 'pairddrad')\n",
    "TTAGGC2.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "TTAGGC2.set_params('filter_min_trim_len', '75')\n",
    "TTAGGC2.set_params('max_alleles_consens', 3)\n",
    "TGACCA2.set_params('output_formats', \"p, s, k, v\")\n",
    "\n",
    "TTAGGC3.set_params('project_dir', '/rigel/edu/w4050/users/ngs2116/ipyrad')\n",
    "TTAGGC3.set_params('barcodes_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/barcodes_TTAGGC.txt')\n",
    "TTAGGC3.set_params('sorted_fastq_path', '/rigel/edu/w4050/users/ngs2116/ipyrad/TTAGGC3_fastqs/*.gz')\n",
    "TTAGGC3.set_params('filter_adapters', 2)\n",
    "TTAGGC3.set_params('datatype', 'pairddrad')\n",
    "TTAGGC3.set_params('restriction_overhang', 'CATGC, AATTC')\n",
    "TTAGGC3.set_params('filter_min_trim_len', '75')\n",
    "TTAGGC3.set_params('max_alleles_consens', 3)\n",
    "TGACCA3.set_params('output_formats', \"p, s, k, v\")\n",
    "TTAGGC3.get_params() # prints the parameters to the screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Loading in de-multiplexed reads \n",
    "Because I've already de-multiplexed my data and set the 'sorted_fastq_path', I just need to load in the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembly: ACAGTG1\n",
      "[####################] 100%  loading reads         | 0:00:29 | s1 | \n",
      "Assembly: ACAGTG2\n",
      "[####################] 100%  loading reads         | 0:00:06 | s1 | \n",
      "Assembly: ACAGTG3\n",
      "[####################] 100%  loading reads         | 0:00:06 | s1 | \n",
      "Assembly: ATCACG1\n",
      "[####################] 100%  loading reads         | 0:00:10 | s1 | \n",
      "Assembly: ATCACG2\n",
      "[####################] 100%  loading reads         | 0:00:09 | s1 | \n",
      "Assembly: ATCACG3\n",
      "[####################] 100%  loading reads         | 0:00:10 | s1 | \n",
      "Assembly: CGATGT1\n",
      "[####################] 100%  loading reads         | 0:00:11 | s1 | \n",
      "Assembly: CGATGT2\n",
      "[####################] 100%  loading reads         | 0:00:10 | s1 | \n",
      "Assembly: CGATGT3\n",
      "[####################] 100%  loading reads         | 0:00:11 | s1 | \n",
      "Assembly: GCCAAT1\n",
      "[####################] 100%  loading reads         | 0:00:05 | s1 | \n",
      "Assembly: GCCAAT2\n",
      "[####################] 100%  loading reads         | 0:00:06 | s1 | \n",
      "Assembly: GCCAAT3\n",
      "[####################] 100%  loading reads         | 0:00:06 | s1 | \n",
      "Assembly: TGACCA1\n",
      "[####################] 100%  loading reads         | 0:00:07 | s1 | \n",
      "Assembly: TGACCA2\n",
      "[####################] 100%  loading reads         | 0:00:07 | s1 | \n",
      "Assembly: TGACCA3\n",
      "[####################] 100%  loading reads         | 0:00:07 | s1 | \n",
      "Assembly: TTAGGC1\n",
      "[####################] 100%  loading reads         | 0:00:08 | s1 | \n",
      "Assembly: TTAGGC2\n",
      "[####################] 100%  loading reads         | 0:00:11 | s1 | \n",
      "Assembly: TTAGGC3\n",
      "[####################] 100%  loading reads         | 0:00:16 | s1 | \n"
     ]
    }
   ],
   "source": [
    "ACAGTG1.run(\"1\", ipyclient=ipyclient)\n",
    "ACAGTG2.run(\"1\", ipyclient=ipyclient) \n",
    "ACAGTG3.run(\"1\", ipyclient=ipyclient) \n",
    "    \n",
    "ATCACG1.run(\"1\", ipyclient=ipyclient) \n",
    "ATCACG2.run(\"1\", ipyclient=ipyclient) \n",
    "ATCACG3.run(\"1\", ipyclient=ipyclient) \n",
    "\n",
    "CGATGT1.run(\"1\", ipyclient=ipyclient) \n",
    "CGATGT2.run(\"1\", ipyclient=ipyclient) \n",
    "CGATGT3.run(\"1\", ipyclient=ipyclient) \n",
    "\n",
    "GCCAAT1.run(\"1\", ipyclient=ipyclient) \n",
    "GCCAAT2.run(\"1\", ipyclient=ipyclient)\n",
    "GCCAAT3.run(\"1\", ipyclient=ipyclient)\n",
    "\n",
    "TGACCA1.run(\"1\", ipyclient=ipyclient)\n",
    "TGACCA2.run(\"1\", ipyclient=ipyclient)\n",
    "TGACCA3.run(\"1\", ipyclient=ipyclient)\n",
    "\n",
    "TTAGGC1.run(\"1\", ipyclient=ipyclient)\n",
    "TTAGGC2.run(\"1\", ipyclient=ipyclient)\n",
    "TTAGGC3.run(\"1\", ipyclient=ipyclient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.5: Merging reads\n",
    "\n",
    "The six libraries from each the three lanes can be merged before step 2. Because the three demultiplexed lanes each use the same barcodes file the samples will have identical names - ipyrad will recognize this during merging and read input files for each library in step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lts_full_assembly = ip.merge(\"lts_full_assembly\", [ACAGTG1, ACAGTG2, ACAGTG3, ATCACG1, ATCACG2, ATCACG3, CGATGT1, CGATGT2, CGATGT3, GCCAAT1, GCCAAT2, GCCAAT3, TGACCA1, TGACCA2, TGACCA3, TTAGGC1, TTAGGC2, TTAGGC3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   assembly_name               lts_full_assembly                            \n",
      "1   project_dir                 /rigel/edu/w4050/users/ngs2116/ipyrad        \n",
      "2   raw_fastq_path                                                           \n",
      "3   barcodes_path               Merged: ACAGTG1, ACAGTG2, ACAGTG3, ATCACG1, ATCACG2, ATCACG3, CGATGT1, CGATGT2, CGATGT3, GCCAAT1, GCCAAT2, GCCAAT3, TGACCA1, TGACCA2, TGACCA3, TTAGGC1, TTAGGC2, TTAGGC3\n",
      "4   sorted_fastq_path                                                        \n",
      "5   assembly_method             denovo                                       \n",
      "6   reference_sequence                                                       \n",
      "7   datatype                    pairddrad                                    \n",
      "8   restriction_overhang        ('CATGC', 'AATTC')                           \n",
      "9   max_low_qual_bases          5                                            \n",
      "10  phred_Qscore_offset         33                                           \n",
      "11  mindepth_statistical        6                                            \n",
      "12  mindepth_majrule            6                                            \n",
      "13  maxdepth                    10000                                        \n",
      "14  clust_threshold             0.85                                         \n",
      "15  max_barcode_mismatch        0                                            \n",
      "16  filter_adapters             2                                            \n",
      "17  filter_min_trim_len         75                                           \n",
      "18  max_alleles_consens         3                                            \n",
      "19  max_Ns_consens              (5, 5)                                       \n",
      "20  max_Hs_consens              (8, 8)                                       \n",
      "21  min_samples_locus           4                                            \n",
      "22  max_SNPs_locus              (20, 20)                                     \n",
      "23  max_Indels_locus            (8, 8)                                       \n",
      "24  max_shared_Hs_locus         0.5                                          \n",
      "25  trim_reads                  (0, 0, 0, 0)                                 \n",
      "26  trim_loci                   (0, 0, 0, 0)                                 \n",
      "27  output_formats              ('p', 's', 'k', 'v')                         \n",
      "28  pop_assign_file                                                          \n"
     ]
    }
   ],
   "source": [
    "lts_full_assembly.get_params() #checking params to ensure proper parmaeter carry over after merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Filtering using quality scores\n",
    "Step 2 uses the quality score recorded in the fastQ data files to filter low quality base calls. Sites with a score below a set value are changed into “N”s (value is set by `max_Ns_consens` in Step 5), and reads with more than the number of allowed “N”s are discarded. The threshold for inclusion is set with the `phred_Qscore_offset` parameter. An optional filter can be applied to remove adapters/primers (see `filter_adapters`), and there is an optional filter to clean up the edges of poor quality reads (see `edit_cutsites`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembly: lts_full_assembly\n",
      "[####################] 100%  concatenating inputs  | 0:18:05 | s2 | \n",
      "[####################] 100%  processing reads      | 1:28:41 | s2 | \n"
     ]
    }
   ],
   "source": [
    "lts_full_assembly.run(\"2\", ipyclient=ipyclient) #runs step 2 with the fully merged assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the objects after Step 2 for future loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lts_full_assembly.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading assembly objects \n",
    "When you run a `.run()` function, you will save all the directions to the results and outputs in a `.json` file. So we don't need to re-run the time-intensive steps we've already run, we load the `.json` objects that already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Assembly: lts_full_assembly\n",
      "from saved path: /rigel/edu/w4050/users/ngs2116/ipyrad/lts_full_assembly.json\n"
     ]
    }
   ],
   "source": [
    "lts_full_assembly = ip.load_json(\"/rigel/edu/w4050/users/ngs2116/ipyrad/lts_full_assembly.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Clustering within individuals\n",
    "Step 3 first dereplicates the sequences from step 2, recording the number of times each unique read is observed. If the data are paired-end, which they are here, it then uses vsearch to merge paired reads which overlap. Since the data are going to be assembled denovo, the resulting data are de novo clustered using `vsearch`. If I were using a reference genome I would be using using `smalt` and `bedtools`. Reads are matched together on the basis of sequence similarity and the resulting clusters are aligned using `muscle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembly: lts_full_assembly\n",
      "[####################] 100%  dereplicating         | 0:37:57 | s3 | \n",
      "[#                   ]   7%  clustering            | 1:55:06 | s3 | "
     ]
    }
   ],
   "source": [
    "lts_full_assembly.run(\"3\", ipyclient=ipyclient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After step 3, I dropped samples that have insufficient reads: WARF007, MUCK006, CAPO003, CAPO004, CAPO006, & STRI003: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_list = [i for i in lts_full_assembly.samples.keys() if i not in [\"WARF007\", \"MUCK006\", \"CAPO003\", \"CAPO004\", \"CAPO006\", \"STRI003\"]]\n",
    "lts_full_assembly.branch(\"lts_ex6\", subsamples=keep_list) #lts_ex6 is the new library name for the assembly object without the six dropped reads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of this analysis, I will only be using the 44 samples from the Wickecheoke to shorten the analysis time. Below I've prepared the separation of the stream samples and the pond samples for future branching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wick_list = [i for i in lts_full_assembly.samples.keys() if i not in [\"WICK010\", \"WICK009\", \"WICK003\", \"WICK004\", \"UPP019\", \"WICK005\", \"UPP002\", \"UPP003\", \"UPP004\", \"UPP006\", \"UPP020\", \"WICK002\", \"WICK006\", \"WICK007\", \"WICK008\", \"UPP016\", \"OLD001\", \"OLD002\", \"WICK011\", \"WICK012\", \"WICK013\", \"WICK014\", \"OLD005\", \"OLD006\", \"OLD007\", \"OLD008\", \"OLD009\", \"WICK015\", \"UPP017\", \"UPP018\", \"UPP021\", \"UPP022\", \"UPP008\", \"UPP009\", \"UPP010\", \"UPP011\", \"UPP012\", \"UPP013\", \"UPP014\", \"UPP015\", \"OLD003\", \"OLD004\", \"UPP001\", \"UPP007\"]\n",
    "lts_full_assembly.branch(\"lts_wick\", subsamples=wick_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pond_list = [i for i in lts_full_assembly.samples if \"SWAR\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"WHIT\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"SVEN\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"MUCK\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"MUKA\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"MUTH\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"WPOA\" in i]\n",
    "lts_full_assembly.branch(\"lts_ponds\", subsamples=pond_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_list = [i for i in lts_full_assembly.samples if \"CAPO\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"HAKI\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"HARI\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"LNIS\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"WARF\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"LOCK\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"STRI\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"MILL\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"WICK\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"UPP\" in i] +\\\n",
    "        [i for i in lts_full_assembly.samples if \"OLD\" in i] +\\\n",
    "lts_full_assembly.branch(\"lts_streams\", subsamples=stream_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Joint estimation of heterozygosity and error rate\n",
    "Step4 jointly estimates sequencing error rate and heterozygosity based on counts of site patterns across clustered reads. These estimates are used in step5 for consensus base calling. If the max_alleles_consens is set to 1 (haploid) then heterozygosity is fixed to 0 and only error rate is estimated. For all other settings of max_alleles_consens a diploid model is used (i.e., two alleles are expected to occur equally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lts_ex6.run(\"4\", ipyclient=ipyclient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Consensus base calling and filtering\n",
    "Step5 estimates consensus allele sequences from clustered reads given the estimated parameters from step 4 and a binomial model. During this step we filter for maximum number of undetermined sites (Ns) per locus (max_Ns_consens). The number of alleles at each locus is recorded, but a filter for max_alleles is not applied until step7. Read depth information is also stored at this step for the VCF output in step7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lts_ex6.run(\"5\", ipyclient=ipyclient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Clustering / Mapping reads among Samples and alignment\n",
    "Step6 clusters consensus sequences across Samples using the same assembly method as in step 3. One allele is randomly sampled before clustering so that ambiguous characters have a lesser effect on clustering, but the resulting data retain information for heterozygotes. The clustered sequences are then aligned using muscle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lts_ex6.run(\"6\", ipyclient=ipyclient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Filtering and formatting output files\n",
    "Step7 applies filters to the final alignments and saves the final data in a number of possible output formats. This step is most often repeated at several different settings for the parameter 21. min_samples_locus to create different assemblies with different proportions of missing data (see branching_workflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lts_ex6.run(\"7\", ipyclient=ipyclient)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
